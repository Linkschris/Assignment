{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the west coast corpus is: 2139911 bytes\n",
      "The size of the east coast corpus is: 3494039 bytes\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import Text\n",
    "\n",
    "\n",
    "corpus_root_east = '/Users/jonas/Documents/DTU/Social Graphs and Interactions/Week 7/text/eastcoasttexts'\n",
    "\n",
    "corpus_root_west = '/Users/jonas/Documents/DTU/Social Graphs and Interactions/Week 7/text/westcoasttexts'\n",
    "\n",
    "#create new corpus only west coast\n",
    "\n",
    "# delete all empty files in the dictonary\n",
    "import os\n",
    "for filename in os.listdir(corpus_root_west):\n",
    "    if os.path.getsize(corpus_root_west + '/' + filename) == 0:\n",
    "        os.remove(corpus_root_west + '/' + filename)\n",
    "\n",
    "for filename in os.listdir(corpus_root_east):\n",
    "    if os.path.getsize(corpus_root_east + '/' + filename) == 0:\n",
    "        os.remove(corpus_root_east + '/' + filename)\n",
    "\n",
    "rapper_corpus_west = PlaintextCorpusReader(corpus_root_west, '.*\\.txt')\n",
    "rapper_text_west = Text(rapper_corpus_west.words())\n",
    "\n",
    "rapper_corpus_east = PlaintextCorpusReader(corpus_root_east, '.*\\.txt')\n",
    "rapper_text_east = Text(rapper_corpus_east.words())\n",
    "\n",
    "rapper_tokens_west = rapper_text_west.tokens\n",
    "rapper_tokens_east = rapper_text_east.tokens\n",
    "\n",
    "#print the size in bites of the corpus\n",
    "import os\n",
    "total_size_west = 0\n",
    "total_size_east = 0\n",
    "for filename in os.listdir(corpus_root_west):\n",
    "    total_size_west += os.path.getsize(corpus_root_west + '/' + filename)\n",
    "for filename in os.listdir(corpus_root_east):\n",
    "    total_size_east += os.path.getsize(corpus_root_east + '/' + filename)\n",
    "\n",
    "print('The size of the west coast corpus is: ' + str(total_size_west) + ' bytes')\n",
    "print('The size of the east coast corpus is: ' + str(total_size_east) + ' bytes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all punctuation from your list of tokens\n",
    "import string\n",
    "punctuation = string.punctuation\n",
    "rapper_tokens_west = [word for word in rapper_tokens_west if word not in punctuation]\n",
    "rapper_tokens_east = [word for word in rapper_tokens_east if word not in punctuation]\n",
    "\n",
    "# Set everything to lower case\n",
    "rapper_tokens_west = [word.lower() for word in rapper_tokens_west]\n",
    "rapper_tokens_east = [word.lower() for word in rapper_tokens_east]\n",
    "\n",
    "# Lemmatize your words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "rapper_tokens_west = [wnl.lemmatize(word) for word in rapper_tokens_west]\n",
    "rapper_tokens_east = [wnl.lemmatize(word) for word in rapper_tokens_east]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('rapper_tokens_west.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(rapper_tokens_west)\n",
    "\n",
    "with open('rapper_tokens_east.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(rapper_tokens_east)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "business_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
